python llm_attack_text_full.py
python llm_attack_text_full.py --dataset safebench_tiny